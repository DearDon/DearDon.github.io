<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="中文&English">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=6.7.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.7.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.7.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Abstract:用VirtualBox装了３个ubuntu10.04的32位系统，并在该环境下装了hadoop-2.5.2。">
<meta name="keywords" content="data-science">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop分布式集群搭建">
<meta property="og:url" content="www.deardon.win/2016/09/17/hadoop-install/index.html">
<meta property="og:site_name" content="D.P">
<meta property="og:description" content="Abstract:用VirtualBox装了３个ubuntu10.04的32位系统，并在该环境下装了hadoop-2.5.2。">
<meta property="og:locale" content="中文&English">
<meta property="og:updated_time" content="2019-01-26T02:23:07.178Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop分布式集群搭建">
<meta name="twitter:description" content="Abstract:用VirtualBox装了３个ubuntu10.04的32位系统，并在该环境下装了hadoop-2.5.2。">






  <link rel="canonical" href="www.deardon.win/2016/09/17/hadoop-install/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Hadoop分布式集群搭建 | D.P</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="中文&English">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">D.P</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives<span class="badge">16</span></a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="www.deardon.win/2016/09/17/hadoop-install/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Don">
      <meta itemprop="description" content="学习，记录，交流，分享...">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="D.P">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Hadoop分布式集群搭建

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2016-09-17 00:00:00" itemprop="dateCreated datePublished" datetime="2016-09-17T00:00:00+08:00">2016-09-17</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2019-01-26 10:23:07" itemprop="dateModified" datetime="2019-01-26T10:23:07+08:00">2019-01-26</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/hadoop/" itemprop="url" rel="index"><span itemprop="name">hadoop</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract:"></a>Abstract:</h3><p>用VirtualBox装了３个ubuntu10.04的32位系统，并在该环境下装了hadoop-2.5.2。<br><br><a id="more"></a></p>
<h3 id="Content"><a href="#Content" class="headerlink" title="Content:"></a>Content:</h3><p>Hadoop已经火了很久了，自己也对它也有好奇心挺久了，记得因为它自己才正式接触学习的java(mapreduce框架是基于Java的)。<br><br>看了一些资料后，为了更直观地体验一下hadoop的集群能力，决定在自己的pc上安装试一下。为了模拟真实的分布式环境，用VirtualBox装了３个ubuntu10.04的32位系统，并在该环境下装了hadoop-2.5.2。由于hadoop要求相对较新的java环境，因此安装了<code>jdk1.7.0_79</code>。<br><br>下面安装过程基于自己的实际经历，亲测有效，但其它环境无法保证。</p>
<p>对分布式hadoop具体的安装可以从系统搭建，ssh,java,hadoop几方面分为４步：</p>
<h4 id="1-搭建用于安装hadoop的系统环境"><a href="#1-搭建用于安装hadoop的系统环境" class="headerlink" title="1. 搭建用于安装hadoop的系统环境"></a>1. 搭建用于安装hadoop的系统环境</h4><h5 id="1-1-利用虚拟机建立三个节点"><a href="#1-1-利用虚拟机建立三个节点" class="headerlink" title="1.1. 利用虚拟机建立三个节点:"></a>1.1. 利用虚拟机建立三个节点:</h5><p>由于要实现真分布式的hadoop安装(集群中结点不止一个)，需要先搭建好集群环境。当然真实的集群肯定是不同的物理机，同时利用各结点的计算能力，才是分布式的作用。这里因为只是为了体验，就直接在自己pc上配合虚拟机来搭环境了。</p>
<p>利用VirtualBox在同一台pc上安装了三个ubuntu10.04的虚拟机系统，具体怎么装就不多说了，可以自己去找VirtualBox的资料。用一台来作master节点，另两台作为slave。设置主机名分别为master-desktop，slave1-desktop, slave2-desktop(合理的主机名可以更直观地区分各节点，且之后ssh时用主机名也比ip更方便，且避免配置出现hardcode)。三台机器的用户名要设置为相同(原因除了通用各节点文件权限，还有ssh免密登陆，总之hadoop有此要求)，如都为hadoop。</p>
<h5 id="1-2-实现虚拟机互连"><a href="#1-2-实现虚拟机互连" class="headerlink" title="1.2. 实现虚拟机互连:"></a>1.2. 实现虚拟机互连:</h5><p>由于是虚拟系统，有个问题要解决——各节点间的通信。刚装好时默认情况各节点是不互连的，我们可以通过将virtualbox的网卡设置为桥接方式来使其互通。如果虚拟机已经设置了NAT用来连外网，为了不影响上外网功能，可以新增虚拟网卡(VirtualBox的网络设置时自带最多4个虚拟网卡)。设置桥接方式的虚拟网卡时将网卡设置为有线的，并自行随意设置一个mac地址(如080027039F60)，Ipv4的地址设置为自动获取。但要注意mac和IPV4地址不能相同冲突。<br><br><strong>注意:</strong>要在系统的网络连接时确保上桥接网卡能成功连上，有时候自动分配IP不成功，就可以尝试手动分配IP。手动设置IP为合法的内网段地址，但要注意各机器的IP在同一网段(如10.133.24.235, 10.133.24.236…)，且不相同，掩码按通常的设就行(255.255.255.0)，网关设置无所谓(可设为10.133.24.1)，因为我们不需要通过它连外网。再尝试连接，一定要保证我们设置的桥接网卡能连接，各节点间能用桥接网卡的ip地址相互ping通。不然不能互相访问节点，分布式也就无从谈起了。</p>
<p>为了之后描述方便，假设三个节点的IP对应如下：</p>
<pre><code>Hostname        IP
master-desktop  10.133.24.235    
slave1-desktop  10.133.24.228    
slave2-desktop  10.133.24.229    
</code></pre><h4 id="2-安装ssh-并设置免密登陆"><a href="#2-安装ssh-并设置免密登陆" class="headerlink" title="2. 安装ssh,并设置免密登陆"></a>2. 安装ssh,并设置免密登陆</h4><p>有了能实现相互ping通的三个节点机后，接下来要利用ssh来实现互连远程控制(这也是master控制slave的实现方式)。由于ssh默认是要输入帐户密码的，为了满足hadoop的频繁ssh操作。hadoop要求各节点间能免密直接ssh。</p>
<h5 id="2-1-安装ssh"><a href="#2-1-安装ssh" class="headerlink" title="2.1. 安装ssh:"></a>2.1. 安装ssh:</h5><p>大部分的Linux系统应该都是有预装ssh的。若没有，在ubuntu下直接 sudo apt-get install openssh-server（也可install ssh)即可。可用sudo ps -e|grep ssh看是否有sshd服务启动，如无，用sudo service ssh start启动</p>
<h5 id="2-2-配置主机名代替IP"><a href="#2-2-配置主机名代替IP" class="headerlink" title="2.2. 配置主机名代替IP:"></a>2.2. 配置主机名代替IP:</h5><p>标准的ssh方式是<code>$ ssh $username@$hostaddress</code>，然后根据提示输入密码。<br><br>由于前面我们已经设置了各节点的用户名均相同(hadoop),因此我们之后的ssh都不用指定远程登陆的用户名(hadoop)，程序会默认用本地的用户名(hadoop)，我们只要给定节点地址$hostaddress就行了,命令简化为<code>$ ssh $hostaddress</code>。<br><br>由于ip地址可能不同开关机后会变，这样配置文件里都会需要更改，不利于维护。我们设置主机名代替IP作为连接时的$hostaddress。对三个节点，分别修改/etc/hosts文件，添加如下内容:</p>
<pre><code>10.133.24.235    master-desktop
10.133.24.228    slave1-desktop
10.133.24.229    slave2-desktop
</code></pre><p>并在/etc/hostname内容修改为对应节点的主机名,如节点master-desktop将hostname文件内容改为master-desktop，其它节点同理修改。现在ssh命令进一步简化为了<code>$ ssh $hostname</code>，但仍然要输入密码。</p>
<h5 id="2-3-配置用公私钥代替密码登陆"><a href="#2-3-配置用公私钥代替密码登陆" class="headerlink" title="2.3. 配置用公私钥代替密码登陆:"></a>2.3. 配置用公私钥代替密码登陆:</h5><p>利用公私钥对，可实现数字签名，身份验证等功能，以下我们设置用其做免密登陆。<br></p>
<ol>
<li>先生成公密钥对，在机器A的~/.ssh目录下输入<code>ssh-keygen -t rsa</code>，即可生成私钥文件d_rsa和公钥文件id_rsa.pub，其中-t 后表示加密算法，除rsa外，dsa也是常用的算法。</li>
<li>然后将id_rsa.pub的内容(内容较长，小心复制)追加到机器B的~/.ssh目录下authorized_keys的文件中(要求用户名相同，若该文件不存在可新建)。则从机器A上ssh到该机器B时，A会用秘钥加密验证信息，B则用authorized_keys中的每个公钥一一测试能否解密，解密成功，则说明A是被授权的免密登陆机器，可直接免密登陆B。这里的A和B可以是同一机器，并通过ssh localhost尝试免密登陆本机来验证ssh配置正确否。</li>
<li>hadoop要求的ssh流程不仅包括master-&gt;slave，还有master-&gt;master(但没有slave-&gt;master或slave-&gt;slave)。因此要求master上生成rsa的公私钥后，将id_rsa.pub内容不仅要添加到到slave1,slave2的authorized_keys里，还要加到master自己的authorized_keys中。</li>
</ol>
<p>至此，为装hadoop而做的免密ssh就设置完了，命令变成了只要输入<code>$ ssh $hostname</code>，无需密码即可快速登陆远程机。</p>
<h4 id="3-安装并设置Java环境"><a href="#3-安装并设置Java环境" class="headerlink" title="3. 安装并设置Java环境"></a>3. 安装并设置Java环境</h4><p>该安装对三个节点完全相同，为了保险起见，最好集郡里各主机上的hadoop,java安装路径完全一致。。Java的安装比较简单，有可能系统还自带了。若没有，直接上网下载对应系统的编译后tar包，版本最后不要太旧。在此只简单说明(不会的直接上网找，一大把)。将jdk的tar.gz包解压到安装目录(假设为/usr/local/jdk1.7.0_79)，设定PATH，JAVA_HOME,JRE_HOME,CLASSPATH环境变量即可，具体为在.bashrc中加入以下内容:</p>
<pre><code>export JAVA_HOME=/usr/local/jdk1.7.0_79
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH
export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
</code></pre><p>可用java —version检验是否装成功</p>
<h4 id="4-安装hadoop及配置"><a href="#4-安装hadoop及配置" class="headerlink" title="4. 安装hadoop及配置"></a>4. 安装hadoop及配置</h4><h5 id="4-1-下载安装hadoop"><a href="#4-1-下载安装hadoop" class="headerlink" title="4.1. 下载安装hadoop"></a>4.1. 下载安装hadoop</h5><p>该安装对三个节点完全相同。可直接搜索下载对应系统编译后tar包，这样不用重编译。安装很简单，直接将tar.gz解压到安装目录(假设/home/hadoop/hadoop-2.5.2)，然后.bashrc里设定如下环境变量。</p>
<pre><code>export HADOOP_HOME=~/hadoop-2.5.2
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
</code></pre><h5 id="4-2-hadoop配置"><a href="#4-2-hadoop配置" class="headerlink" title="4.2. hadoop配置:"></a>4.2. hadoop配置:</h5><p>主要有三类文件要配置, 有的文件(如slaves)只需要在master上配置，slave节点中不需要。但是安全起见，建议全部配置，保持master和slave节点的hadoop安装配置完全一致。<br><br><strong>4个xml文件:core-site.xml,hdfs-site.xml,mapred-site.xml,yarn-site.xml</strong></p>
<p>core-site.xml原文件改为</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;   
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;   
    &lt;value&gt;/home/hadoop/tmp&lt;/value&gt;   
    &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;   
    &lt;/property&gt;   
    &lt;property&gt;   
    &lt;name&gt;fs.defaultFS&lt;/name&gt;   
    &lt;value&gt;hdfs://master-desktop:9000&lt;/value&gt;   
    &lt;/property&gt;   
    &lt;property&gt;   
    &lt;name&gt;io.file.buffer.size&lt;/name&gt;   
    &lt;value&gt;4096&lt;/value&gt;   
    &lt;/property&gt;   
&lt;/configuration&gt;
</code></pre><p>hdfs-site.xml原文件改为</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;   
    &lt;name&gt;dfs.nameservices&lt;/name&gt;   
    &lt;value&gt;hadoop-cluster1&lt;/value&gt;   
    &lt;/property&gt;   
    &lt;property&gt;   
    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
    &lt;value&gt;master-desktop:50090&lt;/value&gt;
    &lt;/property&gt;   
    &lt;property&gt;   
    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;   
    &lt;value&gt;file:///home/hadoop/dfs/name&lt;/value&gt;   
    &lt;/property&gt;   
    &lt;property&gt;   
    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;   
    &lt;value&gt;file:///home/hadoop/dfs/data&lt;/value&gt;   
    &lt;/property&gt;   
    &lt;property&gt;   
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;2&lt;/value&gt;   
    &lt;/property&gt;   
    &lt;property&gt;   
    &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;   
    &lt;value&gt;true&lt;/value&gt;   
    &lt;/property&gt;   
&lt;/configuration&gt;
</code></pre><p>mapred-site.xml原文件改为</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobtracker.http.address&lt;/name&gt;
        &lt;value&gt;master-desktop:50030&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
        &lt;value&gt;master-desktop:10020&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
        &lt;value&gt;master-desktop:19888&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>yarn-site.xml原文件改为</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
        &lt;value&gt;master-desktop:8032&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
        &lt;value&gt;master-desktop:8030&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
        &lt;value&gt;master-desktop:8031&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
        &lt;value&gt;master-desktop:8033&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
        &lt;value&gt;master-desktop:8088&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p><strong>2个env.sh文件:hadoop-env.sh,yarn-env.sh</strong></p>
<p>两个文件的最后均添加一行</p>
<pre><code>export JAVA_HOME=/usr/local/jdk1.7.0_79
</code></pre><p><strong>1个slaves文件:slaves</strong></p>
<p>slaves文件内容改为(若没有，则新建)</p>
<pre><code>slave1-desktop
slave2-desktop
</code></pre><p>老版本还有master文件，2.5.2取消了。</p>
<h4 id="5-hadoop启动和检验"><a href="#5-hadoop启动和检验" class="headerlink" title="5. hadoop启动和检验"></a>5. hadoop启动和检验</h4><p>设置完成后，就可以尝试启动了。正常情况下，所有hadoop操作均只需要在master上进行。</p>
<pre><code>$ hdfs namenode -format #仅第一次启动时要先格式化文件
$ start-dfs.sh #启动dfs服务
$ start-yarn.sh #启动yarn
</code></pre><p>启动成功后可查看进程<code>$ jps</code><br>可浏览器访问服务<code>http://10.0.1.100:50070/</code><br>若要关闭</p>
<pre><code>stop-dfs.sh
stop-yarn.sh
</code></pre><h3 id="Questions"><a href="#Questions" class="headerlink" title="Questions:"></a>Questions:</h3><p>搭建过程中可能遇到的一些问题：</p>
<h4 id="1-不匹配的库的warning"><a href="#1-不匹配的库的warning" class="headerlink" title="1. 不匹配的库的warning"></a>1. 不匹配的库的warning</h4><p>在.bashrc设置环境变量，这一步不是必须的，当有如下问题才需要。启动hadoop时可能出现提示</p>
<pre><code>Starting namenodes on [OpenJDK 64-Bit Server VM warning: You have loaded library /opt/lib/native/libhadoop.so which might have disabled stack guard. The VM will try to fix the stack guard now.
It&#39;s highly recommended that you fix the library with &#39;execstack -c &lt;libfile&gt;&#39;, or link it with &#39;-z noexecstack&#39;.
master-desktop]
</code></pre><p>这是提示有些库不匹配，64-bit java vs 32-bit hadoop and os。这只是一个java的warning,本来不影响hadoop使用，但是该warning输出信息却和之后的主机名重定向到了一起，破坏了合法的主机名(这其实应该算hadoop的bug，这种设计不合理)，因此之后可能报一堆ssh到主机不成功，或主机名异常的问题。在此我们可设置让该warning消息不输出(有人说下面的设置对64操作系统无效，自己是32bit，反正是有效，因此没有再深钻)，在.bashrc 里加上下面设置,千万注意，设置完后，要source一下，不然不会生效。</p>
<pre><code>export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_HOME/lib&quot;
</code></pre><h4 id="2-dfs-namenode等配置文件内容错误"><a href="#2-dfs-namenode等配置文件内容错误" class="headerlink" title="2. dfs.namenode等配置文件内容错误"></a>2. dfs.namenode等配置文件内容错误</h4><p>当启动时出现类似下面的错误提示时，往往就是那几个配置文件出错了。两个sh文件都是只加入了java的安装路径，主要的配置在xml文件中，问题应该出在那。</p>
<pre><code>java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddresses(DFSUtil.java:840)
at   org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:151)
at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:745)
at org.apache.hadoop.hdfs.server.datanode.DataNode.&lt;init&gt;(DataNode.java:278)
</code></pre><p>该问题最最需要注意的是<xml>标签内的空格不会被忽略，尤其从网上copy时容易出现标签与内容间有多空格的情况:<tag>value</tag>变成<tag> value </tag>。这个问题很隐，要注意。</xml></p>
<p>此外，dfs.namenode就是core-site.xml里的dfs.defaultFS，旧版本里xml是配置为dfs.defaultname，2.5.2已经改为dfs.defaultFS了。</p>
<h4 id="3-ssh-need-to-configure-yes-for-first-time"><a href="#3-ssh-need-to-configure-yes-for-first-time" class="headerlink" title="3. ssh need to configure yes for first time"></a>3. ssh need to configure yes for first time</h4><p>此外，由于第一次尝试免密登陆时要手动确认(yes)，这在hadoop启动时可能会导致不能自动ssh连接。</p>
<p>因此在启动hadoop前要确保每种要求的连接流程(master-&gt;all slaves, 以及尤其容易忘记的master-&gt;master)都经过先手动连一次(只要一次就行),并输入yes。</p>
<h4 id="4-集群的用户名忘记设为一致了"><a href="#4-集群的用户名忘记设为一致了" class="headerlink" title="4. 集群的用户名忘记设为一致了"></a>4. 集群的用户名忘记设为一致了</h4><p>有可能会事先没有设好各节点相同的用户名，这种情况，如果代价不大，安全起见，最好重新搭建。不想重新来，可参考以下方法为免密互联(ssh)创建同名用户——hadoop</p>
<ol>
<li>原用户下sudo useradd hadoop,创建用户名,并用sudo passwd hadoop根据提示为其设置密码(不设置密码不能使用该用户)</li>
<li>原用户下在/home目录sudo mkdir hadoop，为该用户创建用户目录，再用sudo chown hadoop hadoop和sudo chgrp hadoop hadoop，将该用户目录所有者和所属用户组改为hadoop(其中hadoop的用户组是在useradd创建用户时默认创建同来的同名组)</li>
<li>给hadoop赋予sudo权限,原用户下sudo usermod -a -G admin hadoop(注意!!现在为此的3步均是在原用户下操作，并未用hadoop登陆)</li>
<li>为新用户拷贝配置文件.bashrc，由于要使其所有者为hadoop，因此我们改用hadoop登陆,登陆后，打开命令行，会发现命令行环境明显有问题，补全等功能都用不了，这个之后会解决，先将原用户的配置文件.bashrc拷到hadoop用户目录下(/home/hadoop/),并确认其所属者和组均为hadoop</li>
<li>继续留在hadoop用户环境下，并设置SHELL由默认的sh变为bash(不改会使tab补全，上下记录和命令提示符显示都有问题),可先用echo $SHELL看当前的SHELL值，然后使用sudo usermod -s /bin/bash hadoop改变其值，改完后，要注销用户并重登陆才能看到效果。</li>
</ol>
<p>至此，新建的hadoop用户和原始的用户功能基本一样了，可以用于搭建hadoop系统用。</p>
<h3 id="History"><a href="#History" class="headerlink" title="History:"></a>History:</h3><ul>
<li><em>2016-09-17</em>:简单记录Hadoop的安装流程及遇到的问题<br></li>
<li><em>2016-09-20</em>:修正ip设置错误和部分描述<br></li>
</ul>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/data-science/" rel="tag"># data-science</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/09/15/python-singleton/" rel="next" title="Python实现单例模式">
                <i class="fa fa-chevron-left"></i> Python实现单例模式
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/09/21/numpy-scipy/" rel="prev" title="Ubuntu16.04为python安装numpy,scipy模块">
                Ubuntu16.04为python安装numpy,scipy模块 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Don</p>
              <p class="site-description motion-element" itemprop="description">学习，记录，交流，分享...</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">16</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">6</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Abstract"><span class="nav-number">1.</span> <span class="nav-text">Abstract:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Content"><span class="nav-number">2.</span> <span class="nav-text">Content:</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-搭建用于安装hadoop的系统环境"><span class="nav-number">2.1.</span> <span class="nav-text">1. 搭建用于安装hadoop的系统环境</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-1-利用虚拟机建立三个节点"><span class="nav-number">2.1.1.</span> <span class="nav-text">1.1. 利用虚拟机建立三个节点:</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#1-2-实现虚拟机互连"><span class="nav-number">2.1.2.</span> <span class="nav-text">1.2. 实现虚拟机互连:</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-安装ssh-并设置免密登陆"><span class="nav-number">2.2.</span> <span class="nav-text">2. 安装ssh,并设置免密登陆</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-安装ssh"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.1. 安装ssh:</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-配置主机名代替IP"><span class="nav-number">2.2.2.</span> <span class="nav-text">2.2. 配置主机名代替IP:</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-配置用公私钥代替密码登陆"><span class="nav-number">2.2.3.</span> <span class="nav-text">2.3. 配置用公私钥代替密码登陆:</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-安装并设置Java环境"><span class="nav-number">2.3.</span> <span class="nav-text">3. 安装并设置Java环境</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-安装hadoop及配置"><span class="nav-number">2.4.</span> <span class="nav-text">4. 安装hadoop及配置</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#4-1-下载安装hadoop"><span class="nav-number">2.4.1.</span> <span class="nav-text">4.1. 下载安装hadoop</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#4-2-hadoop配置"><span class="nav-number">2.4.2.</span> <span class="nav-text">4.2. hadoop配置:</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-hadoop启动和检验"><span class="nav-number">2.5.</span> <span class="nav-text">5. hadoop启动和检验</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Questions"><span class="nav-number">3.</span> <span class="nav-text">Questions:</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-不匹配的库的warning"><span class="nav-number">3.1.</span> <span class="nav-text">1. 不匹配的库的warning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-dfs-namenode等配置文件内容错误"><span class="nav-number">3.2.</span> <span class="nav-text">2. dfs.namenode等配置文件内容错误</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-ssh-need-to-configure-yes-for-first-time"><span class="nav-number">3.3.</span> <span class="nav-text">3. ssh need to configure yes for first time</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-集群的用户名忘记设为一致了"><span class="nav-number">3.4.</span> <span class="nav-text">4. 集群的用户名忘记设为一致了</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#History"><span class="nav-number">4.</span> <span class="nav-text">History:</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Don</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v6.7.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=6.7.0"></script>

  <script src="/js/src/motion.js?v=6.7.0"></script>



  
  


  <script src="/js/src/schemes/muse.js?v=6.7.0"></script>




  
  <script src="/js/src/scrollspy.js?v=6.7.0"></script>
<script src="/js/src/post-details.js?v=6.7.0"></script>



  


  <script src="/js/src/bootstrap.js?v=6.7.0"></script>



  


  


  





  

  

  

  

  
  

  
  

  


  

  

  

  

  

  

  

  

</body>
</html>
